-- =====================================================
-- OMNIA - RAG Schema v2 (Clean Restart with sender column)
-- =====================================================
-- Date: 2025-11-03
-- Description: Complete rebuild of RAG embeddings system with sender filtering
-- Changes from v1:
--   - Added 'sender' column to filter bot vs user messages
--   - Updated match_messages() to filter by sender='bot' by default
--   - Drops and recreates everything for clean slate
-- Impact: Deletes all existing embeddings (will regenerate for bot messages only)

BEGIN;

-- =====================================================
-- STEP 1: DROP EXISTING SCHEMA
-- =====================================================

-- Drop function first (depends on table)
DROP FUNCTION IF EXISTS match_messages;

-- Drop table with cascade (removes all indexes, policies, etc.)
DROP TABLE IF EXISTS message_embeddings CASCADE;

-- =====================================================
-- STEP 2: CREATE TABLE WITH SENDER COLUMN
-- =====================================================

CREATE TABLE message_embeddings (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  chat_id TEXT NOT NULL REFERENCES chats(id) ON DELETE CASCADE,
  message_id UUID NOT NULL REFERENCES messages(id) ON DELETE CASCADE,
  content TEXT NOT NULL,
  sender TEXT NOT NULL CHECK (sender IN ('user', 'bot')),  -- NEW: Filter bot vs user
  embedding VECTOR(768),  -- Vertex AI text-embedding-005 (768 dimensions)
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

COMMENT ON TABLE message_embeddings IS
  'Stores vector embeddings for semantic search across conversation history. Only bot messages are embedded (answers, not questions).';

COMMENT ON COLUMN message_embeddings.sender IS
  'Message sender: "user" or "bot". We only generate embeddings for bot messages (answers) to retrieve relevant context, not user questions.';

COMMENT ON COLUMN message_embeddings.embedding IS
  'Vector embedding (768 dimensions) generated by Vertex AI text-embedding-005 model.';

-- =====================================================
-- STEP 3: CREATE INDEXES
-- =====================================================

-- HNSW index for fast vector similarity search (cosine distance)
CREATE INDEX message_embeddings_embedding_idx
  ON message_embeddings
  USING hnsw (embedding vector_cosine_ops)
  WITH (m = 16, ef_construction = 64);

COMMENT ON INDEX message_embeddings_embedding_idx IS
  'HNSW (Hierarchical Navigable Small World) index for fast approximate nearest neighbor search. Optimized for cosine similarity.';

-- Performance indexes for filtering
CREATE INDEX message_embeddings_user_id_idx ON message_embeddings(user_id);
CREATE INDEX message_embeddings_chat_id_idx ON message_embeddings(chat_id);
CREATE INDEX message_embeddings_sender_idx ON message_embeddings(sender);
CREATE INDEX message_embeddings_created_at_idx ON message_embeddings(created_at DESC);

-- Compound index for common query pattern (user + sender)
CREATE INDEX message_embeddings_user_sender_idx ON message_embeddings(user_id, sender);

-- =====================================================
-- STEP 4: CREATE SEMANTIC SEARCH FUNCTION
-- =====================================================

CREATE OR REPLACE FUNCTION match_messages(
  query_embedding VECTOR(768),
  match_threshold FLOAT DEFAULT 0.5,
  match_count INT DEFAULT 5,
  filter_chat_id TEXT DEFAULT NULL,      -- NULL = search all chats
  filter_user_id UUID DEFAULT NULL,      -- NULL = current user
  filter_sender TEXT DEFAULT 'bot'       -- NEW: Default to bot messages only
)
RETURNS TABLE (
  id UUID,
  message_id UUID,
  chat_id TEXT,
  content TEXT,
  sender TEXT,           -- NEW: Include sender in response
  similarity FLOAT,
  created_at TIMESTAMPTZ
)
LANGUAGE SQL STABLE
SECURITY DEFINER
AS $$
  SELECT
    message_embeddings.id,
    message_embeddings.message_id,
    message_embeddings.chat_id,
    message_embeddings.content,
    message_embeddings.sender,
    1 - (message_embeddings.embedding <=> query_embedding) AS similarity,
    message_embeddings.created_at
  FROM message_embeddings
  WHERE
    -- User filter (default to current authenticated user)
    message_embeddings.user_id = COALESCE(filter_user_id, auth.uid())
    -- Chat filter (NULL = search across all user's chats)
    AND (filter_chat_id IS NULL OR message_embeddings.chat_id = filter_chat_id)
    -- Sender filter (NULL = all senders, 'bot' = bot only, 'user' = user only)
    AND (filter_sender IS NULL OR message_embeddings.sender = filter_sender)
    -- Similarity threshold (only return results above threshold)
    AND 1 - (message_embeddings.embedding <=> query_embedding) > match_threshold
  ORDER BY message_embeddings.embedding <=> query_embedding
  LIMIT match_count;
$$;

COMMENT ON FUNCTION match_messages IS
  'Semantic similarity search using cosine distance. Returns top-k messages above threshold, ordered by similarity. By default searches ALL user chats and returns ONLY bot messages (answers).';

-- =====================================================
-- STEP 5: ROW LEVEL SECURITY (RLS)
-- =====================================================

-- Enable RLS
ALTER TABLE message_embeddings ENABLE ROW LEVEL SECURITY;

-- Users can only view their own embeddings
CREATE POLICY "Users can view own embeddings"
  ON message_embeddings FOR SELECT
  USING (auth.uid() = user_id);

-- Users can insert their own embeddings
CREATE POLICY "Users can insert own embeddings"
  ON message_embeddings FOR INSERT
  WITH CHECK (auth.uid() = user_id);

-- Users can delete their own embeddings
CREATE POLICY "Users can delete own embeddings"
  ON message_embeddings FOR DELETE
  USING (auth.uid() = user_id);

-- Service role can bypass RLS (for batch operations)
-- No explicit policy needed - SECURITY DEFINER functions can bypass RLS

COMMIT;

-- =====================================================
-- VERIFICATION
-- =====================================================
-- After running this migration, verify:
--
-- 1. Table created:
--    SELECT * FROM message_embeddings LIMIT 1;
--
-- 2. Indexes created:
--    SELECT indexname FROM pg_indexes WHERE tablename = 'message_embeddings';
--
-- 3. Function exists:
--    SELECT proname FROM pg_proc WHERE proname = 'match_messages';
--
-- 4. RLS enabled:
--    SELECT tablename, rowsecurity FROM pg_tables WHERE tablename = 'message_embeddings';
--
-- =====================================================
-- USAGE EXAMPLE
-- =====================================================
-- Search for relevant context (bot messages only, across all chats):
--
-- SELECT * FROM match_messages(
--   query_embedding := '[0.1, 0.2, ...]'::vector,
--   match_threshold := 0.5,
--   match_count := 5,
--   filter_chat_id := NULL,      -- Search all chats
--   filter_user_id := NULL,      -- Current user
--   filter_sender := 'bot'       -- Bot messages only (default)
-- );
--
-- Expected result:
-- | id | message_id | chat_id | content | sender | similarity | created_at |
-- |----|------------|---------|---------|--------|------------|------------|
-- | .. | uuid-123   | chat-1  | "..."   | bot    | 0.92       | 2025-11-01 |
-- | .. | uuid-456   | chat-2  | "..."   | bot    | 0.85       | 2025-11-02 |
--
-- =====================================================
-- NEXT STEPS
-- =====================================================
-- 1. Backend: Update /api/generate-embedding.js to store sender='bot'
-- 2. Frontend: Update ragService.js to only generate embeddings for bot messages
-- 3. Backend: Update /api/search-rag.js to pass filter_sender='bot'
-- 4. Backfill: Regenerate embeddings for all existing bot messages
--
